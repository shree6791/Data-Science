{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'\\\\log.txt' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3367ccaa4911>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#.\\log_input\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLOG_INPUT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ISO-8859-1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    797\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 799\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    800\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:3427)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:6861)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: File b'\\\\log.txt' does not exist"
     ]
    }
   ],
   "source": [
    "# Read Data From Source File 'log.txt'\n",
    "\n",
    "LOG_OUTPUT = '.\\log_output'\n",
    "LOG_INPUT = 'log.txt'\n",
    "#.\\log_input\\\n",
    "\n",
    "df = pd.read_table(LOG_INPUT, delimiter=' ', usecols=range(0, 8), header=None, encoding = 'ISO-8859-1', low_memory=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop Invalid Columns\n",
    "df.drop([1,2,4],axis=1,inplace=True)\n",
    "\n",
    "# Rename Column Names\n",
    "df.columns = ['Host', 'Time','Resource','HTTP Reply Code','Bytes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace '-' in the Bytes Column to 0 bytes\n",
    "df['Bytes'].replace('-',0, inplace=True)\n",
    "\n",
    "# Remove '[' from Timestamp\n",
    "df['Time'] = df['Time'].str.lstrip('[')\n",
    "\n",
    "# Split Timestamp data at first instance of ':'\n",
    "df['Time'] = df['Time'].apply(lambda x: x.split(':',1))\n",
    "\n",
    "# Join Timestamp Data such that it's separated by 1 whitespace\n",
    "df['Time'] = df['Time'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "# Modify Data in 'Resource' column to reflect oly the 'Resource' File Path\n",
    "#df['Resource'] = df['Resource'].apply(lambda x: x.split(' ')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert 'Timestamp' column type to Date Time format\n",
    "df['Time'] = df['Time'].apply(pd.to_datetime)\n",
    "\n",
    "# Convert 'Bytes' column type to Numeric Value\n",
    "df['Bytes'] = df['Bytes'].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Convert 'HTTP Reply Code'' column type to Numeric Value\n",
    "df['HTTP Reply Code'] = df['HTTP Reply Code'].apply(pd.to_numeric, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Host</th>\n",
       "      <th>Time</th>\n",
       "      <th>Resource</th>\n",
       "      <th>HTTP Reply Code</th>\n",
       "      <th>Bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199.72.81.55</td>\n",
       "      <td>1995-07-01 00:00:01</td>\n",
       "      <td>POST /login HTTP/1.0</td>\n",
       "      <td>401</td>\n",
       "      <td>1420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unicomp6.unicomp.net</td>\n",
       "      <td>1995-07-01 00:00:06</td>\n",
       "      <td>GET /shuttle/countdown/ HTTP/1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>3985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199.72.81.55</td>\n",
       "      <td>1995-07-01 00:00:09</td>\n",
       "      <td>POST /login HTTP/1.0</td>\n",
       "      <td>401</td>\n",
       "      <td>1420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>burger.letters.com</td>\n",
       "      <td>1995-07-01 00:00:11</td>\n",
       "      <td>GET /shuttle/countdown/liftoff.html HTTP/1.0</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199.72.81.55</td>\n",
       "      <td>1995-07-01 00:00:12</td>\n",
       "      <td>POST /login HTTP/1.0</td>\n",
       "      <td>401</td>\n",
       "      <td>1420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Host                Time  \\\n",
       "0          199.72.81.55 1995-07-01 00:00:01   \n",
       "1  unicomp6.unicomp.net 1995-07-01 00:00:06   \n",
       "2          199.72.81.55 1995-07-01 00:00:09   \n",
       "3    burger.letters.com 1995-07-01 00:00:11   \n",
       "4          199.72.81.55 1995-07-01 00:00:12   \n",
       "\n",
       "                                       Resource  HTTP Reply Code  Bytes  \n",
       "0                          POST /login HTTP/1.0              401   1420  \n",
       "1              GET /shuttle/countdown/ HTTP/1.0              200   3985  \n",
       "2                          POST /login HTTP/1.0              401   1420  \n",
       "3  GET /shuttle/countdown/liftoff.html HTTP/1.0              304      0  \n",
       "4                          POST /login HTTP/1.0              401   1420  "
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add Time Zone to Time Stamp\n",
    "#df['Time'].apply(lambda x : x.tz_localize('US/Eastern'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 1:\n",
    "List the top 10 most active Host/IP addresses that have accessed the site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TOP_10_HOST = df['Host'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write Top 10 Host/IP addresses that have accessed the site to file\n",
    "\n",
    "TOP_10_HOST.to_csv('LOG_OUTPUT/hosts.txt', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 2:\n",
    "Identify the 10 resources that consume the most bandwidth on the site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BYTES = df.groupby(['Resource'])['Bytes'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RESOURCE = df.groupby(['Resource'])['Resource'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TOP_10_BW = (BYTES * RESOURCE).sort_values(ascending = False).head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write Top 10 Resources that consumes highest Bandwidth to file\n",
    "\n",
    "resources = open(\"LOG_OUTPUT/resources.txt\",'w')\n",
    "\n",
    "for key,value in TOP_10_BW.iteritems():\n",
    "    resources_output = ''.join([key.split(\" \")[1],'\\n'])\n",
    "    resources.write(resources_output)\n",
    "    \n",
    "resources.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 3:\n",
    "List the top 10 busiest (or most frequently visited) 60-minute periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.index = df['Time']\n",
    "end_time = df['Time'].max()\n",
    "start_time = df['Time'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_time = start_time\n",
    "total_time_interval = (end_time - start_time).total_seconds() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_time_interval = int(total_time_interval) + 1\n",
    "end_time = current_time + pd.Timedelta(seconds=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visited_map = {}\n",
    "\n",
    "for i in range(total_time_interval):\n",
    "    \n",
    "    visited_count = df[(df['Time'] >= start_time) & (df['Time'] <= end_time)].count()['Host']    \n",
    "    \n",
    "    date_f = start_time.strftime('%d/%b/%Y:%H:%M:%S -0400')\n",
    "    \n",
    "    visited_map[date_f] = visited_count\n",
    "    start_time = start_time + pd.Timedelta(seconds=1)\n",
    "    end_time = start_time + pd.Timedelta(seconds=3600)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write Top 10 60 minute interval of high site access to file \n",
    "\n",
    "hours_access = open(\"LOG_OUTPUT/hours.txt\",'w')\n",
    "\n",
    "i = 0\n",
    "\n",
    "for key,value in sorted(visited_map.items(),reverse = False):\n",
    "\n",
    "    i += 1\n",
    "    if(i>10):        \n",
    "        break\n",
    "    \n",
    "    hours_output = (\"\".join([key,',',str(value),'\\n']))\n",
    "    hours_access.write(hours_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 4:\n",
    "\n",
    "Detect patterns of three failed login attempts from the same IP address over 20 seconds so that all further attempts to the site can be blocked for 5 minutes. Log those possible security breaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "host_unique = df['Host'].unique()\n",
    "N = len(host_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buffer = {}\n",
    "max_attempt = 3\n",
    "error_status = 401\n",
    "wait_time_blocked = 300\n",
    "wait_time_unblocked = 20\n",
    "\n",
    "for i in range(N):\n",
    "    \n",
    "    buffer[host_unique[i]] = {}\n",
    "    buffer[host_unique[i]]['attempt'] = 0    \n",
    "    buffer[host_unique[i]]['wait_time'] = 0\n",
    "    buffer[host_unique[i]]['blocked'] = False\n",
    "    buffer[host_unique[i]]['total_wait_time'] = wait_time_unblocked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end_time = df['Time'].max()\n",
    "start_time = df['Time'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_time = start_time\n",
    "total_time = (end_time - start_time).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_time = int(total_time) + 1\n",
    "blocked_hosts = open(\"LOG_OUTPUT/blocked.txt\",'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(total_time):       \n",
    "    \n",
    "    current_time_values = df[df['Time']==current_time]\n",
    "    \n",
    "    for _, j in current_time_values.iterrows():\n",
    "        \n",
    "        buffer[j['Host']]['wait_time'] += 1\n",
    "\n",
    "        # Do When Not In Blocked State\n",
    "        if buffer[j['Host']]['blocked'] == False:\n",
    "\n",
    "            # Check for UnSuccessful Attempt\n",
    "            if j['HTTP Reply Code'] == error_status:\n",
    "                buffer[j['Host']]['attempt'] += 1\n",
    "            \n",
    "            # Goto Blocked State\n",
    "            if buffer[j['Host']]['attempt'] == max_attempt:\n",
    "                buffer[j['Host']]['total_wait_time'] = wait_time_blocked                  \n",
    "                buffer[j['Host']]['blocked'] = True\n",
    "                \n",
    "            # Reset Timer of Host if Successful Transmission\n",
    "            if buffer[j['Host']]['wait_time'] <= wait_time_unblocked and j['HTTP Reply Code'] != error_status:\n",
    "                buffer[j['Host']]['attempt'] = 0    \n",
    "                buffer[j['Host']]['wait_time'] = 0\n",
    "                buffer[j['Host']]['blocked'] = False\n",
    "                buffer[j['Host']]['total_wait_time'] = wait_time_unblocked\n",
    "        \n",
    "        else: \n",
    "            \n",
    "            # LOG failed attempts in blocked state\n",
    "            \n",
    "            date_f = j['Time'].strftime('[%d/%b/%Y:%H:%M:%S -0400]')\n",
    "\n",
    "            line_file_output = ''.join([j['Host'], ' - - ' , date_f, ' \"', j['Resource'], '\" ', \n",
    "                         str(j['HTTP Reply Code']), ' ', str(j['Bytes']),'\\n'])\n",
    "\n",
    "            blocked_hosts.write(line_file_output)\n",
    "            \n",
    "            # Come Out Of Blocked State\n",
    "            if buffer[j['Host']]['wait_time'] ==  buffer[j['Host']]['total_wait_time']:\n",
    "                \n",
    "                buffer[j['Host']]['attempt'] = 0    \n",
    "                buffer[j['Host']]['wait_time'] = 0\n",
    "                buffer[j['Host']]['blocked'] = False\n",
    "                buffer[j['Host']]['total_wait_time'] = wait_time_unblocked\n",
    "   \n",
    "    current_time = current_time + pd.Timedelta(seconds=1)\n",
    "    \n",
    "blocked_hosts.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 5\n",
    "List the Top 10 Busiest Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.index = df['Time']\n",
    "COUNT = df.groupby([df.index.date,df.index.hour]).size()\n",
    "TIMESTAMP = df.groupby([df.index.date,df.index.hour]).nth(0)['Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOP_10_BUSY_PERIOD = [TIMESTAMP, COUNT]\n",
    "TOP_10_BUSY_PERIOD = pd.concat(TOP_10_BUSY_PERIOD, axis = 1)\n",
    "TOP_10_BUSY_PERIOD.sort_values(by=[0], ascending = False).head(10) \n",
    "TOP_10_BUSY_PERIOD.to_csv('LOG_OUTPUT/hours_best.txt', sep=',', index=False, header=False, date_format='%d/%b/%Y:%H:%M:%S -0400')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
